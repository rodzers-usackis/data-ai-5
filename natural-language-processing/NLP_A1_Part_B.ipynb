{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "from pathlib import Path\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Span"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# This contains the processing pipeline\n",
    "# As well as language-specific rules for tokenization etc.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import text files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "moby_dick = Path('../Text Files/moby_dick.txt').read_text(encoding='utf8')\n",
    "moby_dick = moby_dick.replace('\\n', '')\n",
    "doc_1 = nlp(moby_dick)\n",
    "\n",
    "ai_forecast_1 = Path('../Text Files/ai_forecast1.txt').read_text(encoding='utf8')\n",
    "ai_forecast_1 = ai_forecast_1.replace('\\n', '')\n",
    "doc_2 = nlp(ai_forecast_1)\n",
    "\n",
    "ai_forecast_2 = Path('../Text Files/ai_forecast2.txt').read_text(encoding='utf8')\n",
    "ai_forecast_2 = ai_forecast_2.replace('\\n', '')\n",
    "doc_3 = nlp(ai_forecast_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare the three documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between moby_dick and ai_forecast_1 is: 0.8268866081548163\n",
      "\n",
      "Similarity between moby_dick and ai_forecast_2 is: 0.8658625494727867\n",
      "\n",
      "Similarity between ai_forecast_1 and ai_forecast_2 is: 0.9873224403687386\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between {} and {} is: {}\\n'.format('moby_dick', 'ai_forecast_1', doc_1.similarity(doc_2)))\n",
    "print('Similarity between {} and {} is: {}\\n'.format('moby_dick', 'ai_forecast_2', doc_1.similarity(doc_3)))\n",
    "print('Similarity between {} and {} is: {}'.format('ai_forecast_1', 'ai_forecast_2', doc_2.similarity(doc_3)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare the first one hundred tokens of each document with each other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the first one hundred tokens of moby_dick and ai_forecast_1 is: 0.7518677711486816\n",
      "\n",
      "Similarity between the first one hundred tokens of moby_dick and ai_forecast_2 is: 0.816913902759552\n",
      "\n",
      "Similarity between the first one hundred tokens of ai_forecast_1 and ai_forecast_2 is: 0.9578762650489807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_1_tokens = doc_1[0:99]\n",
    "doc_2_tokens = doc_2[0:99]\n",
    "doc_3_tokens = doc_3[0:99]\n",
    "\n",
    "print('Similarity between the first one hundred tokens of {} and {} is: {}\\n'.format('moby_dick', 'ai_forecast_1', doc_1_tokens.similarity(doc_2_tokens)))\n",
    "print('Similarity between the first one hundred tokens of {} and {} is: {}\\n'.format('moby_dick', 'ai_forecast_2', doc_1_tokens.similarity(doc_3_tokens)))\n",
    "print('Similarity between the first one hundred tokens of {} and {} is: {}\\n'.format('ai_forecast_1', 'ai_forecast_2', doc_2_tokens.similarity(doc_3_tokens)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start from a blank nlp model and add your name to the entities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rodžers Ušackis.\n",
      "Rodžers Ušackis PERSON\n",
      "\n",
      "Named Entity - Rodžers Ušackis\n",
      "Entity Label - PERSON\n",
      "Entity Label Description - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "nlp_2 = spacy.blank(\"en\")\n",
    "\n",
    "words = ['My', 'name', 'is', 'Rodžers', 'Ušackis', '.']\n",
    "spaces = [True, True, True, True, False, False]\n",
    "\n",
    "doc_4 = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc_4.text)\n",
    "\n",
    "# 3, 5 is the start and end token of the span, so in this case it takes the 3rd and 4th token - Rodžers Ušackis\n",
    "span = Span(doc_4, 3, 5, label='PERSON')\n",
    "print(span.text, span.label_, end='\\n\\n')\n",
    "\n",
    "# Add your name to the entities\n",
    "doc_4.ents = [span]\n",
    "\n",
    "for ent in doc_4.ents:\n",
    "    # Print the entity text , it's label and explanation\n",
    "    print('Named Entity - {}\\nEntity Label - {}\\nEntity Label Description - {}'.format(ent.text, ent.label_, spacy.explain(ent.label_)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
