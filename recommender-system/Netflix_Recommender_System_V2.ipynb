{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Recommender Systems Assignment\n",
    "Rodžers Ušackis, ACS301"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### About The Project"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Type Of Recommendation System\n",
    "\n",
    "The recommendation system type I chose for this assignment is **collaborative filtering** recommender system."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset Used\n",
    "\n",
    "The dataset I chose for this assignment is an actual dataset that Netflix themselves provided for their open competition,\n",
    "in which they gave a task to improve their existing recommendation system.\n",
    "\n",
    "[Wikipedia Info About The Competition](https://en.wikipedia.org/wiki/Netflix_Prize)\n",
    "\n",
    "Note:\n",
    "I initially wanted to use the original [Dataset](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data) which was provided by netflix, but due to memory issues/errors I opted for a [reduced dataset](https://www.kaggle.com/datasets/rishitjavia/netflix-movie-rating-dataset).\n",
    "\n",
    "It fits the requirements necessary for a **collaborative filtering** recommender system by having **user-item ratings**.\n",
    "\n",
    "In this case, it has various training datasets, which contain:\n",
    "- MovieIDs range from 1 to 17770 sequentially.\n",
    "- CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\n",
    "- Ratings are on a five star (integral) scale from 1 to 5.\n",
    "- Dates have the format YYYY-MM-DD.\n",
    "\n",
    "As well as a file which can be used for decrypting movie ID's to actual titles and release dates.\n",
    "\n",
    "It contains:\n",
    "- MovieID do not correspond to actual Netflix movie ids or IMDB movie ids.\n",
    "- YearOfRelease can range from 1890 to 2005 and may correspond to the release of corresponding DVD, not necessarily its theaterical release.\n",
    "- Title is the Netflix movie title and may not correspond to titles used on other sites. Titles are in English.\n",
    "\n",
    "\n",
    "##### Note:\n",
    "\n",
    "While doing the assignment, I ran into memory issues, so I decided to scale down the operation.\n",
    "\n",
    "Maybe I could look into the big data aspect of the real assignment later on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Libraries Used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import deque"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building A Recommender System"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Movie Titles Dataset\n",
    "\n",
    "First, we import the movie titles dataset.\n",
    "\n",
    "Since someone didn't think about using ';' as a seperator for the csv file, I ran into an error when trying to read movie titles which contained a comma.\n",
    "\n",
    "e.g.\n",
    "*72,1974,At Home Among Strangers, A Stranger Among His Own*\n",
    "\n",
    "Since the movie title uses the same character, which is used for the seperator, an error is thrown, since it expects three columns, but found four.\n",
    "\n",
    "To counter that, I wrote a function that joins the two columns of the bad lines of the csv file into one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def manual_separation(bad_line):\n",
    "\n",
    "    # This if statement is written only for displaying purposes, I didn't want to print every line.\n",
    "    if bad_line[0] == '72':\n",
    "        print(bad_line)\n",
    "\n",
    "    right_split = bad_line[:-2] + [\",\".join(bad_line[-2:])]\n",
    "\n",
    "    return right_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['72', '1974', 'At Home Among Strangers', ' A Stranger Among His Own']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17118/1007737952.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  movie_titles_list_raw = pd.read_csv('datasets/original-netflix-dataset/movie_titles.csv', encoding='ISO-8859-1', names=['Movie ID', 'Year', 'Name'],\n"
     ]
    }
   ],
   "source": [
    "movie_titles_list_raw = pd.read_csv('datasets/original-netflix-dataset/movie_titles.csv', encoding='ISO-8859-1', names=['Movie ID', 'Year', 'Name'],\n",
    "    engine='python', on_bad_lines=manual_separation).set_index('Movie ID')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I didn't like the fact that the 'Year' column was being stored as a float64 type, were this a larger dataset, it would clog up a lot of memory.\n",
    "\n",
    "So I decided to convert it to type int, but first I had to drop rows with NaN values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "movie_titles_list_raw.dropna(inplace=True)\n",
    "movie_titles_list_raw['Year'] = movie_titles_list_raw['Year'].astype('int')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title Dataset\n",
      "-------------------\n",
      "Shape: (17763, 2)\n",
      "-------------------\n",
      "Dtypes: \n",
      "Year     int64\n",
      "Name    object\n",
      "dtype: object\n",
      "-------------------\n",
      "Size: 1671134\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "          Year                                               Name\n",
      "Movie ID                                                         \n",
      "1         2003                                    Dinosaur Planet\n",
      "2         2004                         Isle of Man TT 2004 Review\n",
      "3         1997                                          Character\n",
      "4         1994                       Paula Abdul's Get Up & Dance\n",
      "5         2004                           The Rise and Fall of ECW\n",
      "...        ...                                                ...\n",
      "68        2004                                        Invader Zim\n",
      "69        2003                               WWE: Armageddon 2003\n",
      "70        1999                              Tai Chi: The 24 Forms\n",
      "71        1995                    Maya Lin: A Strong Clear Vision\n",
      "72        1974  At Home Among Strangers, A Stranger Among His Own\n",
      "\n",
      "[72 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f'Movie Title Dataset\\n'\n",
    "      f'-------------------'\n",
    "      f'\\nShape: {movie_titles_list_raw.shape}\\n'\n",
    "      f'-------------------'\n",
    "      f'\\nDtypes: \\n{movie_titles_list_raw.dtypes}\\n'\n",
    "      f'-------------------'\n",
    "      f'\\nSize: {sys.getsizeof(movie_titles_list_raw)}\\n'\n",
    "      f'-------------------------------------------------------------------'\n",
    "      f'\\n\\n{movie_titles_list_raw.head(72)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, row 72 has been taken care of, so have the other rows which run into the same issue."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Movie User Ratings Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "      User  Rating        Date\n0       1:     NaN         NaN\n1  1488844     3.0  2005-09-06\n2   822109     5.0  2005-05-13\n3   885013     4.0  2005-10-19\n4    30878     4.0  2005-12-26",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Rating</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1:</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1488844</td>\n      <td>3.0</td>\n      <td>2005-09-06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>822109</td>\n      <td>5.0</td>\n      <td>2005-05-13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>885013</td>\n      <td>4.0</td>\n      <td>2005-10-19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30878</td>\n      <td>4.0</td>\n      <td>2005-12-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_1_list_raw = pd.read_csv('datasets/original-netflix-dataset/combined_data_1.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "# combined_data_2_list_raw = pd.read_csv('datasets/original-netflix-dataset/combined_data_2.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "# combined_data_3_list_raw = pd.read_csv('datasets/original-netflix-dataset/combined_data_3.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "# combined_data_4_list_raw = pd.read_csv('datasets/original-netflix-dataset/combined_data_4.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "combined_data_1_list_raw.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first row is the issue we're faced with.\n",
    "\n",
    "Instead of the dataset being:\n",
    "- **'movie, user, rating, date'**\n",
    "\n",
    "It is:\n",
    " - **'movie: user, rating, date'**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_1_list_raw[combined_data_1_list_raw['Rating'].isna()]['User'].reset_index()\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "\n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_1_list_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_1_list_raw.loc[df_id_1+1:].copy()\n",
    "\n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie'] = movie_id\n",
    "\n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_data_complete_list_final = pd.concat(user_data)\n",
    "\n",
    "# Remove variables from memory\n",
    "del user_data, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id, combined_data_1_list_raw\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since there were some data type issues with this dataset as well, I decided to make some changes here also.\n",
    "\n",
    "Namely:\n",
    "- Rating\n",
    "    - float64 -> int64\n",
    "- User\n",
    "    - object -> int64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset before: 3718210513\n",
      "Size of the dataset after: 2381322652\n",
      "\n",
      "Memory usage reduced by: 1336887861 (56% smaller)\n"
     ]
    }
   ],
   "source": [
    "before = sys.getsizeof(combined_data_complete_list_final)\n",
    "print(f'Size of the dataset before: {before}')\n",
    "\n",
    "combined_data_complete_list_final['Rating'] = combined_data_complete_list_final['Rating'].astype('int')\n",
    "combined_data_complete_list_final['User'] = combined_data_complete_list_final['User'].astype('int')\n",
    "\n",
    "after = sys.getsizeof(combined_data_complete_list_final)\n",
    "print(f'Size of the dataset after: {after}\\n\\n'\n",
    "      f'Memory usage reduced by: {abs(before - after)} ({int(abs(((before - after) * 100) / after))}% smaller)')\n",
    "\n",
    "del before, after"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's a lot of memory saved if I do say so myself.\n",
    "\n",
    "This will allow us to work with more data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie User-Ratings Dataset\n",
      "--------------------------\n",
      "Shape: (24053764, 4)\n",
      "--------------------------\n",
      "Dtypes: \n",
      "User       int64\n",
      "Rating     int64\n",
      "Date      object\n",
      "Movie      int64\n",
      "dtype: object\n",
      "--------------------------\n",
      "Size: 2381322652\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "      User  Rating        Date  Movie\n",
      "1  1488844       3  2005-09-06      1\n",
      "2   822109       5  2005-05-13      1\n",
      "3   885013       4  2005-10-19      1\n",
      "4    30878       4  2005-12-26      1\n",
      "5   823519       3  2004-05-03      1\n"
     ]
    }
   ],
   "source": [
    "print(f'Movie User-Ratings Dataset\\n'\n",
    "      f'--------------------------'\n",
    "      f'\\nShape: {combined_data_complete_list_final.shape}\\n'\n",
    "      f'--------------------------'\n",
    "      f'\\nDtypes: \\n{combined_data_complete_list_final.dtypes}\\n'\n",
    "      f'--------------------------'\n",
    "      f'\\nSize: {sys.getsizeof(combined_data_complete_list_final)}\\n'\n",
    "      f'-------------------------------------------------------------------'\n",
    "      f'\\n\\n{combined_data_complete_list_final.head(5)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User      0\n",
      "Rating    0\n",
      "Date      0\n",
      "Movie     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_complete_list_final.isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No null values, that's nice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 470758\n",
      "\n",
      "Number of unique movies: 4499\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique users: {combined_data_complete_list_final.User.nunique()}\\n\\n'\n",
    "      f'Number of unique movies: {combined_data_complete_list_final.Movie.nunique()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Manipulation\n",
    "\n",
    "In order to deal with memory issues, I decided to limit the rows that should qualify for the recommender system.\n",
    "\n",
    "This in theory should also improve the quality of the system.\n",
    "\n",
    "And my approach is as follows:\n",
    "- Remove movies which have too little reviews (not popular)\n",
    "- Remove users who haven't submitted enough reviews (not as active)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum movie rating count threshold: 215.20000000000002\n",
      "Minimum user rating count threshold: 5\n"
     ]
    }
   ],
   "source": [
    "row_count_limit = 300000\n",
    "\n",
    "qualified_ratings = combined_data_complete_list_final[:row_count_limit]\n",
    "\n",
    "movie_rating_counts = qualified_ratings.groupby('Movie')['Rating'].count()\n",
    "minimum_movie_rating_count = movie_rating_counts.quantile(q=0.3)\n",
    "\n",
    "# I will just default this to 2\n",
    "user_rating_counts = qualified_ratings.groupby('User')['Rating'].count()\n",
    "# minimum_user_rating_count = user_rating_counts.quantile(q=0.75)\n",
    "\n",
    "print(f'Minimum movie rating count threshold: {minimum_movie_rating_count}\\n'\n",
    "      f'Minimum user rating count threshold: {5}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "qualified_ratings = qualified_ratings[qualified_ratings['Movie'].isin(movie_rating_counts[movie_rating_counts > minimum_movie_rating_count].index)]\n",
    "\n",
    "qualified_ratings = qualified_ratings[qualified_ratings['User'].isin(user_rating_counts[user_rating_counts > 5].index)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been reduced from 300000 rows to 22250 rows.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = sys.getsizeof(combined_data_complete_list_final)\n",
    "\n",
    "after = sys.getsizeof(qualified_ratings)\n",
    "\n",
    "print(f'The dataset has been reduced from {row_count_limit} rows to {qualified_ratings.shape[0]} rows.\\n')\n",
    "\n",
    "del before, after, row_count_limit, combined_data_complete_list_final\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "Since filtering requires quite a lot of memory resources, we will limit the rating count to 10 thousand."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot table shape: (2989, 54)\n",
      "\n",
      "Movie     1    3    5   6    8   10  12  15   16   17  ...  65  67   68  70  \\\n",
      "User                                                   ...                    \n",
      "1333     NaN  4.0  NaN NaN  3.0 NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "2213     NaN  NaN  NaN NaN  NaN NaN NaN NaN  3.0  NaN  ... NaN NaN  NaN NaN   \n",
      "3321     3.0  NaN  4.0 NaN  1.0 NaN NaN NaN  3.0  2.0  ... NaN NaN  NaN NaN   \n",
      "3998     NaN  NaN  NaN NaN  NaN NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "5652     NaN  NaN  NaN NaN  3.0 NaN NaN NaN  NaN  NaN  ... NaN NaN  4.0 NaN   \n",
      "...      ...  ...  ...  ..  ...  ..  ..  ..  ...  ...  ...  ..  ..  ...  ..   \n",
      "2646515  NaN  NaN  NaN NaN  NaN NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "2646634  NaN  NaN  NaN NaN  NaN NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "2647197  NaN  NaN  NaN NaN  1.0 NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "2648287  NaN  NaN  NaN NaN  NaN NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "2648885  NaN  NaN  NaN NaN  NaN NaN NaN NaN  NaN  NaN  ... NaN NaN  NaN NaN   \n",
      "\n",
      "Movie     71   73  74  75   76   77  \n",
      "User                                 \n",
      "1333     2.0  NaN NaN NaN  NaN  3.0  \n",
      "2213     NaN  4.0 NaN NaN  NaN  4.0  \n",
      "3321     NaN  4.0 NaN NaN  4.0  4.0  \n",
      "3998     NaN  NaN NaN NaN  NaN  4.0  \n",
      "5652     4.0  NaN NaN NaN  NaN  NaN  \n",
      "...      ...  ...  ..  ..  ...  ...  \n",
      "2646515  NaN  NaN NaN NaN  NaN  NaN  \n",
      "2646634  NaN  NaN NaN NaN  5.0  NaN  \n",
      "2647197  NaN  NaN NaN NaN  NaN  4.0  \n",
      "2648287  NaN  NaN NaN NaN  NaN  2.0  \n",
      "2648885  NaN  NaN NaN NaN  NaN  2.0  \n",
      "\n",
      "[2989 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "rating_pivot_table = qualified_ratings.pivot_table(index='User', columns='Movie', values='Rating')\n",
    "mean_user_ratings = rating_pivot_table.mean(axis=1)\n",
    "mean_movie_ratings = rating_pivot_table.T.mean(axis=1)\n",
    "\n",
    "print(f'Pivot table shape: {rating_pivot_table.shape}\\n\\n'\n",
    "      f'{rating_pivot_table}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot table shape: (2989, 54)\n",
      "\n",
      "Movie     1    3    5    6    8    10   12   15   16   17  ...   65   67   68  \\\n",
      "User                                                       ...                  \n",
      "1333     0.0  4.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2213     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  ...  0.0  0.0  0.0   \n",
      "3321     3.0  0.0  4.0  0.0  1.0  0.0  0.0  0.0  3.0  2.0  ...  0.0  0.0  0.0   \n",
      "3998     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "5652     0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2646515  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2646634  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2647197  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2648287  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2648885  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "Movie     70   71   73   74   75   76   77  \n",
      "User                                        \n",
      "1333     0.0  2.0  0.0  0.0  0.0  0.0  3.0  \n",
      "2213     0.0  0.0  4.0  0.0  0.0  0.0  4.0  \n",
      "3321     0.0  0.0  4.0  0.0  0.0  4.0  4.0  \n",
      "3998     0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
      "5652     0.0  4.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...      ...  ...  ...  ...  ...  ...  ...  \n",
      "2646515  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2646634  0.0  0.0  0.0  0.0  0.0  5.0  0.0  \n",
      "2647197  0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
      "2648287  0.0  0.0  0.0  0.0  0.0  0.0  2.0  \n",
      "2648885  0.0  0.0  0.0  0.0  0.0  0.0  2.0  \n",
      "\n",
      "[2989 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Note: As we are subtracting the mean from each rating to standardize\n",
    "# all users with only one rating or who had rated everything the same will be dropped\n",
    "\n",
    "# Drop all columns containing only zeros representing users who did not rate\n",
    "rating_pivot_table.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize the values\n",
    "# rating_pivot_table = rating_pivot_table.apply(lambda x: (x-np.mean(x))/(np.max(x)-np.min(x)), axis=1)\n",
    "\n",
    "print(f'Pivot table shape: {rating_pivot_table.shape}\\n\\n'\n",
    "      f'{rating_pivot_table}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# This is how to get the real id from the rating_pivot_table and vice-versa.\n",
    "# Useful in the future for user_similarity decoding.\n",
    "print(rating_pivot_table.index[0])\n",
    "print(rating_pivot_table.index.get_loc(1333))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### User Based Collaborative Filtering\n",
    "\n",
    "User-based collaborative filtering is a method of making recommendations based on the preferences of similar users.\n",
    "It works by identifying users who have similar tastes and interests, and then recommending items that those similar users have liked.\n",
    "\n",
    "![user-based-collaborative-filtering](images/user_based.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "user_similarity = cosine_similarity(rating_pivot_table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity shape: (2989, 2989)\n",
      "\n",
      "[[1.         0.19131158 0.31151662 ... 0.55865556 0.43278921 0.2318231 ]\n",
      " [0.19131158 1.         0.63869479 ... 0.3301611  0.49404842 0.44918569]\n",
      " [0.31151662 0.63869479 1.         ... 0.54627928 0.55042637 0.43374812]\n",
      " ...\n",
      " [0.55865556 0.3301611  0.54627928 ... 1.         0.59430562 0.37426366]\n",
      " [0.43278921 0.49404842 0.55042637 ... 0.59430562 1.         0.39385955]\n",
      " [0.2318231  0.44918569 0.43374812 ... 0.37426366 0.39385955 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f'User similarity shape: {user_similarity.shape}\\n\\n'\n",
    "      f'{user_similarity}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User  Rating        Date  Movie\n",
      "1       1488844       3  2005-09-06      1\n",
      "4         30878       4  2005-12-26      1\n",
      "8       1248029       3  2004-04-22      1\n",
      "21      1080361       3  2005-03-28      1\n",
      "23       558634       4  2004-12-14      1\n",
      "...         ...     ...         ...    ...\n",
      "300030  1661344       4  2003-08-19     77\n",
      "300035  1045879       2  2003-05-03     77\n",
      "300051   223160       2  2004-05-18     77\n",
      "300058  1814516       4  2004-03-23     77\n",
      "300073   972399       2  2005-04-04     77\n",
      "\n",
      "[22250 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(qualified_ratings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def user_based_cf_recommender(user_id):\n",
    "    # Since user_id != index in between the dataframes,\n",
    "    # we need a way to decode these values.\n",
    "\n",
    "    # Within this function I did it with the variables:\n",
    "    # user_id_to_index and user_index_to_user_id\n",
    "    user_id_to_index = rating_pivot_table.index.get_loc(user_id)\n",
    "\n",
    "    scores = list(enumerate(user_similarity[user_id_to_index]))\n",
    "    sorted_scores = sorted(scores, key= lambda x:x[1], reverse=True)[1:10]\n",
    "\n",
    "    user_index_to_user_id = rating_pivot_table.index[sorted_scores[0][0]]\n",
    "    similar_user_id = user_index_to_user_id\n",
    "    print(f'The most similar user to user {user_id} is user {similar_user_id} with a score of {sorted_scores[0][1]}.\\n')\n",
    "    print(f'Other similar users include:')\n",
    "    for user, score in sorted_scores[1:]:\n",
    "        print(f'ID: {rating_pivot_table.index[user]}\\tScore: {score}')\n",
    "\n",
    "    # Retrieve the movie ID's of the movies that the user has already seen\n",
    "    user_seen_movies = list(set(qualified_ratings[qualified_ratings.User == user_id]['Movie'].values))\n",
    "    print(f'\\nUser {user_id} has seen these movies: {user_seen_movies}.')\n",
    "\n",
    "    # Retrieve the movie ID's that the person most similar to the user has seen before\n",
    "    # the movie IDs that most similar person has seen before\n",
    "    similar_person_seen_movies = list(set(qualified_ratings[qualified_ratings.User == similar_user_id]['Movie'].values))\n",
    "    print(f'User {similar_user_id} has seen these movies: {similar_person_seen_movies}.')\n",
    "\n",
    "    # Return 10 movies which the person most similar to the user has seen, but the user has not yet seen.\n",
    "    # (Difference between the lists)\n",
    "    recommended_movie_ids = list(set(similar_person_seen_movies) - set(user_seen_movies))[:9]\n",
    "    print(f'\\nThese are the movies which we can recommend (unseen movies): {recommended_movie_ids}.')\n",
    "\n",
    "    return movie_titles_list_raw.loc[recommended_movie_ids]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar user to user 1488844 is user 427967 with a score of 0.8388704928078611.\n",
      "\n",
      "Other similar users include:\n",
      "ID: 1137159\tScore: 0.788009048074417\n",
      "ID: 2276333\tScore: 0.7865834032652848\n",
      "ID: 544833\tScore: 0.7856742013183862\n",
      "ID: 1661600\tScore: 0.7803898228929836\n",
      "ID: 2402139\tScore: 0.7602522864777522\n",
      "ID: 1341214\tScore: 0.7516283835227737\n",
      "ID: 2457781\tScore: 0.7465910488440874\n",
      "ID: 1084999\tScore: 0.7423923386456233\n",
      "\n",
      "User 1488844 has seen these movies: [1, 8, 44, 76, 17, 58, 30].\n",
      "User 427967 has seen these movies: [8, 44, 76, 58, 28, 30].\n",
      "\n",
      "These are the movies which we can recommend (unseen movies): [28].\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Year             Name\nMovie ID                       \n28        2002  Lilo and Stitch",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Name</th>\n    </tr>\n    <tr>\n      <th>Movie ID</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>2002</td>\n      <td>Lilo and Stitch</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_cf_recommender(1488844)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: This only works sometimes, depending on the user.\n",
    "\n",
    "I guess now that I'm using a dataset that is much larger than before, there are far too many customers with the same ratings on the same movies.\n",
    "\n",
    "In case something goes wrong, I'm providing a screenshot of a working solution below.\n",
    "\n",
    "![proof](images/proof.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Item Based Collaborative Filtering\n",
    "\n",
    "Item-based collaborative filtering is the recommendation system to use the similarity between items using the ratings by users.\n",
    "The fundamental assumption for this type of collaborative filtering is that the user should, in theory, give similar ratings to similar movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Version 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "item_similarity = cosine_similarity(rating_pivot_table.T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.06436628 0.1459996  ... 0.07357741 0.12991025 0.14930844]\n",
      " [0.06436628 1.         0.05353381 ... 0.10470684 0.08889538 0.07643782]\n",
      " [0.1459996  0.05353381 1.         ... 0.08027002 0.11995224 0.11848327]\n",
      " ...\n",
      " [0.07357741 0.10470684 0.08027002 ... 1.         0.03461641 0.07907354]\n",
      " [0.12991025 0.08889538 0.11995224 ... 0.03461641 1.         0.27704767]\n",
      " [0.14930844 0.07643782 0.11848327 ... 0.07907354 0.27704767 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(item_similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def item_based_cf_recommender(movie_name):\n",
    "    # This time I decided to work with a movie name, so we have to decode that first\n",
    "    movie_idx = movie_titles_list_raw[movie_titles_list_raw['Name'].str.contains(movie_name)].index[0] - 1\n",
    "\n",
    "    specific_movie_correlation = item_similarity[movie_idx]\n",
    "\n",
    "    result = pd.DataFrame({'Score': specific_movie_correlation}).sort_values('Score', ascending=False)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some movies we can choose from for the testing of the function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dinosaur Planet\n",
      "Isle of Man TT 2004 Review\n",
      "Character\n",
      "Paula Abdul's Get Up & Dance\n",
      "The Rise and Fall of ECW\n",
      "Sick\n",
      "8 Man\n",
      "What the #$*! Do We Know!?\n",
      "Class of Nuke 'Em High 2\n",
      "Fighter\n",
      "Full Frame: Documentary Shorts\n",
      "My Favorite Brunette\n",
      "Lord of the Rings: The Return of the King: Extended Edition: Bonus Material\n",
      "Nature: Antarctica\n",
      "Neil Diamond: Greatest Hits Live\n",
      "Screamers\n",
      "7 Seconds\n",
      "Immortal Beloved\n",
      "By Dawn's Early Light\n",
      "Seeta Aur Geeta\n",
      "Strange Relations\n",
      "Chump Change\n",
      "Clifford: Clifford Saves the Day! / Clifford's Fluffiest Friend Cleo\n",
      "My Bloody Valentine\n",
      "Inspector Morse 31: Death Is Now My Neighbour\n",
      "Never Die Alone\n",
      "Sesame Street: Elmo's World: The Street We Live On\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 28):\n",
    "    print(movie_titles_list_raw.loc[i]['Name'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "user = 1488844\n",
    "movie = \"Character\"\n",
    "item_based_df = item_based_cf_recommender(movie)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "       Score\n2   1.000000\n23  0.196157\n34  0.161213\n46  0.149077\n0   0.146000\n18  0.145398\n20  0.139675\n26  0.138521\n41  0.133013\n52  0.119952\n53  0.118483\n14  0.118280\n17  0.115733\n24  0.114704\n16  0.111322\n37  0.105357\n9   0.100610\n8   0.100146\n22  0.098286\n21  0.096514\n13  0.093566\n5   0.089939\n49  0.084512\n51  0.080270\n38  0.077905\n25  0.077229\n10  0.073920\n45  0.073769\n42  0.073439\n3   0.073294\n29  0.072988\n6   0.072858\n43  0.072448\n36  0.070751\n47  0.070305\n33  0.068453\n11  0.067590\n15  0.064955\n50  0.064561\n48  0.060397\n19  0.059482\n4   0.058898\n7   0.057961\n31  0.057091\n39  0.057005\n35  0.055234\n1   0.053534\n12  0.052825\n40  0.052094\n28  0.048816\n30  0.043709\n32  0.041839\n27  0.036764\n44  0.036437",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.196157</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.161213</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.149077</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.146000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.145398</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.139675</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.138521</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.133013</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.119952</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.118483</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.118280</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.115733</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.114704</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.111322</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.105357</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.100610</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.100146</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.098286</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.096514</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.093566</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.089939</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.084512</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.080270</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.077905</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.077229</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.073920</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.073769</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.073439</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.073294</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.072988</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.072858</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.072448</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.070751</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.070305</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.068453</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.067590</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.064955</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.064561</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.060397</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.059482</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.058898</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.057961</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.057091</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.057005</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.055234</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.053534</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.052825</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.052094</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.048816</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.043709</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.041839</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.036764</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.036437</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar movie to \"Character\" is \"My Bloody Valentine\".\n"
     ]
    }
   ],
   "source": [
    "print(f'The most similar movie to \"{movie}\" is \"{movie_titles_list_raw.iloc[item_based_df.index[1]][\"Name\"]}\".')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Version 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def item_based_cf_recommender_2_all_recommendations(user_id, movie_name):\n",
    "    knn = NearestNeighbors(metric='cosine', n_neighbors=rating_pivot_table.shape[1])\n",
    "    knn.fit(rating_pivot_table.T)\n",
    "    distances, indices = knn.kneighbors(rating_pivot_table.T)\n",
    "\n",
    "    movie_idx = movie_titles_list_raw[movie_titles_list_raw['Name'].str.contains(movie_name)].index[0] - 1\n",
    "\n",
    "    # Real movie ID's\n",
    "    indices = pd.DataFrame(indices + 1)\n",
    "    similar_movies = indices.loc[movie_idx, :]\n",
    "\n",
    "    # Inverted distances\n",
    "    inverted_distances = pd.DataFrame(1 - distances)\n",
    "    inverted_movie_distances = inverted_distances.loc[movie_idx, :]\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    # test_df = pd.Series(\n",
    "    #    mean_movie_ratings.loc[movie_idx + 1] + rating_pivot_table.T.iloc[similar_movies].subtract(mean_movie_ratings.loc[similar_movies], axis='index').mul(\n",
    "    #       inverted_movie_distances, axis='index').sum(axis='index') / sum(inverted_movie_distances), name='recommendation')\n",
    "\n",
    "    print_out = f'Movies most similar to \"{movie_name}\"'\n",
    "\n",
    "    print(f'{print_out}')\n",
    "    print('-' * len(print_out))\n",
    "\n",
    "    for movie in similar_movies:\n",
    "        print(f'#{index} - {movie_titles_list_raw.loc[movie][\"Name\"]}\\n'\n",
    "              f'(Movie ID: {movie}\\tDistance: {inverted_movie_distances.loc[index - 1]})\\n')\n",
    "              # f'Predicted Rating: {1})\\n')\n",
    "        index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# mean_user_ratings.loc[user]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# print(mean_movie_ratings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies most similar to \"Character\"\n",
      "----------------------------------\n",
      "#1 - Character\n",
      "(Movie ID: 3\tDistance: 1.0)\n",
      "\n",
      "#2 - My Bloody Valentine\n",
      "(Movie ID: 24\tDistance: 0.1961565351679424)\n",
      "\n",
      "#3 - Ferngully 2: The Magical Rescue\n",
      "(Movie ID: 35\tDistance: 0.1612133403523368)\n",
      "\n",
      "#4 - The Bad and the Beautiful\n",
      "(Movie ID: 47\tDistance: 0.14907676954549254)\n",
      "\n",
      "#5 - Dinosaur Planet\n",
      "(Movie ID: 1\tDistance: 0.14599959559572562)\n",
      "\n",
      "#6 - By Dawn's Early Light\n",
      "(Movie ID: 19\tDistance: 0.1453983399897939)\n",
      "\n",
      "#7 - Strange Relations\n",
      "(Movie ID: 21\tDistance: 0.13967498100234965)\n",
      "\n",
      "#8 - Sesame Street: Elmo's World: The Street We Live On\n",
      "(Movie ID: 27\tDistance: 0.13852070838627473)\n",
      "\n",
      "#9 - Searching for Paradise\n",
      "(Movie ID: 42\tDistance: 0.13301306121428857)\n",
      "\n",
      "#10 - The Bonesetter\n",
      "(Movie ID: 53\tDistance: 0.11995224185897024)\n",
      "\n",
      "#11 - We're Not Married\n",
      "(Movie ID: 54\tDistance: 0.11848326583061597)\n",
      "\n",
      "#12 - Neil Diamond: Greatest Hits Live\n",
      "(Movie ID: 15\tDistance: 0.11827990895640306)\n",
      "\n",
      "#13 - Immortal Beloved\n",
      "(Movie ID: 18\tDistance: 0.11573271164837029)\n",
      "\n",
      "#14 - Inspector Morse 31: Death Is Now My Neighbour\n",
      "(Movie ID: 25\tDistance: 0.11470435794116152)\n",
      "\n",
      "#15 - 7 Seconds\n",
      "(Movie ID: 17\tDistance: 0.11132225518704586)\n",
      "\n",
      "#16 - Daydream Obsession\n",
      "(Movie ID: 38\tDistance: 0.10535666670140609)\n",
      "\n",
      "#17 - Fighter\n",
      "(Movie ID: 10\tDistance: 0.10060975803143979)\n",
      "\n",
      "#18 - Class of Nuke 'Em High 2\n",
      "(Movie ID: 9\tDistance: 0.10014571720947585)\n",
      "\n",
      "#19 - Clifford: Clifford Saves the Day! / Clifford's Fluffiest Friend Cleo\n",
      "(Movie ID: 23\tDistance: 0.09828590130029347)\n",
      "\n",
      "#20 - Chump Change\n",
      "(Movie ID: 22\tDistance: 0.09651396168600224)\n",
      "\n",
      "#21 - Nature: Antarctica\n",
      "(Movie ID: 14\tDistance: 0.09356583446465616)\n",
      "\n",
      "#22 - Sick\n",
      "(Movie ID: 6\tDistance: 0.08993944899885942)\n",
      "\n",
      "#23 - A Yank in the R.A.F.\n",
      "(Movie ID: 50\tDistance: 0.08451226277013002)\n",
      "\n",
      "#24 - The Weather Underground\n",
      "(Movie ID: 52\tDistance: 0.08027002190274135)\n",
      "\n",
      "#25 - Love Reinvented\n",
      "(Movie ID: 39\tDistance: 0.0779052652674016)\n",
      "\n",
      "#26 - Never Die Alone\n",
      "(Movie ID: 26\tDistance: 0.07722872332637287)\n",
      "\n",
      "#27 - Full Frame: Documentary Shorts\n",
      "(Movie ID: 11\tDistance: 0.0739197515055916)\n",
      "\n",
      "#28 - Rudolph the Red-Nosed Reindeer\n",
      "(Movie ID: 46\tDistance: 0.0737690090452503)\n",
      "\n",
      "#29 - Silent Service\n",
      "(Movie ID: 43\tDistance: 0.07343853067697614)\n",
      "\n",
      "#30 - Paula Abdul's Get Up & Dance\n",
      "(Movie ID: 4\tDistance: 0.07329399606255316)\n",
      "\n",
      "#31 - Something's Gotta Give\n",
      "(Movie ID: 30\tDistance: 0.07298804289460081)\n",
      "\n",
      "#32 - 8 Man\n",
      "(Movie ID: 7\tDistance: 0.07285759415147297)\n",
      "\n",
      "#33 - Spitfire Grill\n",
      "(Movie ID: 44\tDistance: 0.07244820045621503)\n",
      "\n",
      "#34 - Zatoichi's Conspiracy\n",
      "(Movie ID: 37\tDistance: 0.0707512625506217)\n",
      "\n",
      "#35 - Justice League\n",
      "(Movie ID: 48\tDistance: 0.0703045810199866)\n",
      "\n",
      "#36 - Ashtanga Yoga: Beginner's Practice with Nicki Doane\n",
      "(Movie ID: 34\tDistance: 0.06845278427192536)\n",
      "\n",
      "#37 - My Favorite Brunette\n",
      "(Movie ID: 12\tDistance: 0.06759000803759874)\n",
      "\n",
      "#38 - Screamers\n",
      "(Movie ID: 16\tDistance: 0.06495535640996597)\n",
      "\n",
      "#39 - Jonah: A VeggieTales Movie: Bonus Material\n",
      "(Movie ID: 51\tDistance: 0.06456104631747106)\n",
      "\n",
      "#40 - Devo: The Complete Truth About De-evolution\n",
      "(Movie ID: 49\tDistance: 0.06039711194197028)\n",
      "\n",
      "#41 - Seeta Aur Geeta\n",
      "(Movie ID: 20\tDistance: 0.05948154320340582)\n",
      "\n",
      "#42 - The Rise and Fall of ECW\n",
      "(Movie ID: 5\tDistance: 0.058898340689063855)\n",
      "\n",
      "#43 - What the #$*! Do We Know!?\n",
      "(Movie ID: 8\tDistance: 0.05796060209671228)\n",
      "\n",
      "#44 - ABC Primetime: Mel Gibson's The Passion of the Christ\n",
      "(Movie ID: 32\tDistance: 0.057091392159796195)\n",
      "\n",
      "#45 - Pitcher and the Pin-Up\n",
      "(Movie ID: 40\tDistance: 0.057004834370819824)\n",
      "\n",
      "#46 - Lady Chatterley\n",
      "(Movie ID: 36\tDistance: 0.05523404911198071)\n",
      "\n",
      "#47 - Isle of Man TT 2004 Review\n",
      "(Movie ID: 2\tDistance: 0.0535338105210158)\n",
      "\n",
      "#48 - Lord of the Rings: The Return of the King: Extended Edition: Bonus Material\n",
      "(Movie ID: 13\tDistance: 0.052824854306472324)\n",
      "\n",
      "#49 - Horror Vision\n",
      "(Movie ID: 41\tDistance: 0.05209402833872545)\n",
      "\n",
      "#50 - Boycott\n",
      "(Movie ID: 29\tDistance: 0.04881630264814296)\n",
      "\n",
      "#51 - Classic Albums: Meat Loaf: Bat Out of Hell\n",
      "(Movie ID: 31\tDistance: 0.04370905538374337)\n",
      "\n",
      "#52 - Aqua Teen Hunger Force: Vol. 1\n",
      "(Movie ID: 33\tDistance: 0.04183937594136644)\n",
      "\n",
      "#53 - Lilo and Stitch\n",
      "(Movie ID: 28\tDistance: 0.03676378135230096)\n",
      "\n",
      "#54 - The Love Letter\n",
      "(Movie ID: 45\tDistance: 0.03643692396865983)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_based_cf_recommender_2_all_recommendations(user, movie)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we compare these results to output [28], then we can see that they are the same.\n",
    "\n",
    "The reason I made a second version for the same filtering type, is that I wanted to get predicted ratings for a specific user, but I ran into many issues throughout the project and spent way too much time trying to fix them."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
